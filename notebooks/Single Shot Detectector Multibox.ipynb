{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Shot MultiBox Detector in TensorFlow\n",
    "\n",
    "SSD is an unified framework for object detection with a single network. It has been originally introduced in this research [article](http://arxiv.org/abs/1512.02325).\n",
    "\n",
    "This repository contains a TensorFlow re-implementation of the original [Caffe code]. At present, it only implements VGG-based SSD networks (with 300 and 512 inputs). Present TF checkpoints have been directly converted from SSD Caffe models.\n",
    "\n",
    "\n",
    "## SSD minimal example\n",
    "\n",
    "The [SSD Notebook](notebooks/single_shot_detector.ipynb) contains a minimal example of the SSD TensorFlow pipeline. Shortly, the detection is made of two main steps: running the SSD network on the image and post-processing the output using common algorithms (top-k filtering and Non-Maximum Suppression algorithm).\n",
    "Here are two examples of successful detection outputs:\n",
    "![](./pictures/ex1.jpg \"SSD anchors\")\n",
    "![](./pictures/ex2.jpg \"SSD anchors\")\n",
    "\n",
    "To run the notebook you first have to unzip the checkpoint files in ./checkpoint\n",
    "```bash\n",
    "unzip ssd_300_vgg.ckpt.zip\n",
    "```\n",
    "and then start a jupyter notebook with\n",
    "```bash\n",
    "jupyter notebook notebooks/ssd_notebook.ipynb\n",
    "```\n",
    "\n",
    "\n",
    "## Datasets\n",
    "\n",
    "The current version only supports Pascal VOC datasets (2007 and 2012). In order to be used for training a SSD model, the former need to be converted to TF-Records using the `tf_convert_data.py` script:\n",
    "```bash\n",
    "DATASET_DIR=./VOC2007/test/\n",
    "OUTPUT_DIR=./tfrecords\n",
    "python tf_convert_data.py \\\n",
    "    --dataset_name=pascalvoc \\\n",
    "    --dataset_dir=${DATASET_DIR} \\\n",
    "    --output_name=voc_2007_train \\\n",
    "    --output_dir=${OUTPUT_DIR}\n",
    "```\n",
    "Note the previous command generated a collection of TF-Records instead of a single file in order to ease shuffling during training.\n",
    "\n",
    "## Evaluation on Pascal VOC 2007\n",
    "\n",
    "The present TensorFlow implementation of SSD models have the following performances:\n",
    "\n",
    "| Model | Training data  | Testing data | mAP | FPS  |\n",
    "|--------|:---------:|:------:|:------:|:------:|\n",
    "| [SSD-300 VGG-based](https://drive.google.com/open?id=0B0qPCUZ-3YwWZlJaRTRRQWRFYXM) | VOC07+12 trainval | VOC07 test | 0.778 | - |\n",
    "| [SSD-300 VGG-based](https://drive.google.com/file/d/0B0qPCUZ-3YwWUXh4UHJrd1RDM3c/view?usp=sharing) | VOC07+12+COCO trainval | VOC07 test | 0.817 | - |\n",
    "| [SSD-512 VGG-based](https://drive.google.com/open?id=0B0qPCUZ-3YwWT1RCLVZNN3RTVEU) | VOC07+12+COCO trainval | VOC07 test | 0.837 | - |\n",
    "\n",
    "After downloading and extracting the previous checkpoints, the evaluation metrics should be reproducible by running the following command:\n",
    "```bash\n",
    "EVAL_DIR=./logs/\n",
    "CHECKPOINT_PATH=./checkpoints/VGG_VOC0712_SSD_300x300_ft_iter_120000.ckpt\n",
    "python eval_ssd_network.py \\\n",
    "    --eval_dir=${EVAL_DIR} \\\n",
    "    --dataset_dir=${DATASET_DIR} \\\n",
    "    --dataset_name=pascalvoc_2007 \\\n",
    "    --dataset_split_name=test \\\n",
    "    --model_name=ssd_300_vgg \\\n",
    "    --checkpoint_path=${CHECKPOINT_PATH} \\\n",
    "    --batch_size=1\n",
    "```\n",
    "The evaluation script provides estimates on the recall-precision curve and compute the mAP metrics following the Pascal VOC 2007 and 2012 guidelines.\n",
    "\n",
    "In addition, if one wants to experiment/test a different Caffe SSD checkpoint, the former can be converted to TensorFlow checkpoints as following:\n",
    "```sh\n",
    "CAFFE_MODEL=./ckpts/SSD_300x300_ft_VOC0712/VGG_VOC0712_SSD_300x300_ft_iter_120000.caffemodel\n",
    "python caffe_to_tensorflow.py \\\n",
    "    --model_name=ssd_300_vgg \\\n",
    "    --num_classes=21 \\\n",
    "    --caffemodel_path=${CAFFE_MODEL}\n",
    "```\n",
    "\n",
    "## Training\n",
    "\n",
    "The script `train_ssd_network.py` is in charged of training the network. Similarly to TF-Slim models, one can pass numerous options to the training process (dataset, optimiser, hyper-parameters, model, ...). In particular, it is possible to provide a checkpoint file which can be use as starting point in order to fine-tune a network.\n",
    "\n",
    "### Fine-tuning existing SSD checkpoints\n",
    "\n",
    "The easiest way to fine the SSD model is to use as pre-trained SSD network (VGG-300 or VGG-512). For instance, one can fine tune a model starting from the former as following:\n",
    "```bash\n",
    "DATASET_DIR=./tfrecords\n",
    "TRAIN_DIR=./logs/\n",
    "CHECKPOINT_PATH=./checkpoints/ssd_300_vgg.ckpt\n",
    "python train_ssd_network.py \\\n",
    "    --train_dir=${TRAIN_DIR} \\\n",
    "    --dataset_dir=${DATASET_DIR} \\\n",
    "    --dataset_name=pascalvoc_2012 \\\n",
    "    --dataset_split_name=train \\\n",
    "    --model_name=ssd_300_vgg \\\n",
    "    --checkpoint_path=${CHECKPOINT_PATH} \\\n",
    "    --save_summaries_secs=60 \\\n",
    "    --save_interval_secs=600 \\\n",
    "    --weight_decay=0.0005 \\\n",
    "    --optimizer=adam \\\n",
    "    --learning_rate=0.001 \\\n",
    "    --batch_size=32\n",
    "```\n",
    "Note that in addition to the training script flags, one may also want to experiment with data augmentation parameters (random cropping, resolution, ...) in `ssd_vgg_preprocessing.py` or/and network parameters (feature layers, anchors boxes, ...) in `ssd_vgg_300/512.py`\n",
    "\n",
    "Furthermore, the training script can be combined with the evaluation routine in order to monitor the performance of saved checkpoints on a validation dataset. For that purpose, one can pass to training and validation scripts a GPU memory upper limit such that both can run in parallel on the same device. If some GPU memory is available for the evaluation script, the former can be run in parallel as follows:\n",
    "```bash\n",
    "EVAL_DIR=${TRAIN_DIR}/eval\n",
    "python eval_ssd_network.py \\\n",
    "    --eval_dir=${EVAL_DIR} \\\n",
    "    --dataset_dir=${DATASET_DIR} \\\n",
    "    --dataset_name=pascalvoc_2007 \\\n",
    "    --dataset_split_name=test \\\n",
    "    --model_name=ssd_300_vgg \\\n",
    "    --checkpoint_path=${TRAIN_DIR} \\\n",
    "    --wait_for_checkpoints=True \\\n",
    "    --batch_size=1 \\\n",
    "    --max_num_batches=500\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nets import ssd_vgg_512, ssd_common, np_methods\n",
    "from preprocessing import ssd_vgg_preprocessing\n",
    "from notebooks import visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TensorFlow session: grow memory when needed. TF, DO NOT USE ALL MY GPU MEMORY!!!\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "config = tf.ConfigProto(log_device_placement=False, gpu_options=gpu_options)\n",
    "isess = tf.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSD 300 Model\n",
    "\n",
    "The SSD 300 network takes 300x300 image inputs. In order to feed any image, the latter is resize to this input shape (i.e.`Resize.WARP_RESIZE`). Note that even though it may change the ratio width / height, the SSD model performs well on resized images (and it is the default behaviour in the original Caffe implementation).\n",
    "\n",
    "SSD anchors correspond to the default bounding boxes encoded in the network. The SSD net output provides offset on the coordinates and dimensions of these anchors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../checkpoints/VGG_VOC0712_SSD_512x512_ft_iter_120000.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Input placeholder.\n",
    "net_shape = (512, 512)\n",
    "data_format = 'NHWC'\n",
    "img_input = tf.placeholder(tf.uint8, shape=(None, None, 3))\n",
    "# Evaluation pre-processing: resize to SSD net shape.\n",
    "image_pre, labels_pre, bboxes_pre, bbox_img = ssd_vgg_preprocessing.preprocess_for_eval(\n",
    "    img_input, None, None, net_shape, data_format, resize=ssd_vgg_preprocessing.Resize.WARP_RESIZE)\n",
    "image_4d = tf.expand_dims(image_pre, 0)\n",
    "\n",
    "# Define the SSD model.\n",
    "reuse = True if 'ssd_net' in locals() else None\n",
    "ssd_net = ssd_vgg_512.SSDNet()\n",
    "with slim.arg_scope(ssd_net.arg_scope(data_format=data_format)):\n",
    "    predictions, localisations, _, _ = ssd_net.net(image_4d, is_training=False, reuse=reuse)\n",
    "\n",
    "# Restore SSD model.\n",
    "#ckpt_filename = '../checkpoints/ssd_300_vgg.ckpt'\n",
    "ckpt_filename = '../checkpoints/VGG_VOC0712_SSD_512x512_ft_iter_120000.ckpt'\n",
    "isess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(isess, ckpt_filename)\n",
    "\n",
    "# SSD default anchor boxes.\n",
    "ssd_anchors = ssd_net.anchors(net_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Post-processing pipeline\n",
    "\n",
    "The SSD outputs need to be post-processed to provide proper detections. Namely, we follow these common steps:\n",
    "\n",
    "* Select boxes above a classification threshold;\n",
    "* Clip boxes to the image shape;\n",
    "* Apply the Non-Maximum-Selection algorithm: fuse together boxes whose Jaccard score > threshold;\n",
    "* If necessary, resize bounding boxes to original image shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Main image processing routine.\n",
    "def process_image(img, select_threshold=0.3, nms_threshold=.45, net_shape=(512, 512)):\n",
    "    # Run SSD network.\n",
    "    rimg, rpredictions, rlocalisations, rbbox_img = isess.run([image_4d, predictions, localisations, bbox_img],\n",
    "                                                              feed_dict={img_input: img})\n",
    "    \n",
    "    # Get classes and bboxes from the net outputs.\n",
    "    rclasses, rscores, rbboxes = np_methods.ssd_bboxes_select(\n",
    "            rpredictions, rlocalisations, ssd_anchors,\n",
    "            select_threshold=select_threshold, img_shape=net_shape, num_classes=21, decode=True)\n",
    "    \n",
    "    rbboxes = np_methods.bboxes_clip(rbbox_img, rbboxes)\n",
    "    # Remove other classes than cars.\n",
    "    idxes = (rclasses == 8)\n",
    "    rclasses = rclasses[idxes]\n",
    "    rscores = rscores[idxes]\n",
    "    rbboxes = rbboxes[idxes]\n",
    "    rclasses, rscores, rbboxes = np_methods.bboxes_sort(rclasses, rscores, rbboxes, top_k=400)\n",
    "    rclasses, rscores, rbboxes = np_methods.bboxes_nms(rclasses, rscores, rbboxes, nms_threshold=nms_threshold)\n",
    "    # Resize bboxes to original image shape. Note: useless for Resize.WARP!\n",
    "    rbboxes = np_methods.bboxes_resize(rbbox_img, rbboxes)\n",
    "    return rclasses, rscores, rbboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: test (1).jpeg\n",
      "File: test (1).jpg\n",
      "File: test (10).jpg\n",
      "File: test (100).jpg\n",
      "File: test (101).jpg\n",
      "File: test (102).jpg\n",
      "File: test (11).jpg\n",
      "File: test (12).jpg\n",
      "File: test (13).jpg\n",
      "File: test (14).jpg\n",
      "File: test (15).jpg\n",
      "File: test (16).jpg\n",
      "File: test (17).jpg\n",
      "File: test (18).jpg\n",
      "File: test (19).jpg\n",
      "File: test (2).jpeg\n",
      "File: test (2).jpg\n",
      "File: test (20).jpg\n",
      "File: test (21).jpg\n",
      "File: test (22).jpg\n",
      "File: test (23).jpg\n",
      "File: test (24).jpg\n",
      "File: test (25).jpg\n",
      "File: test (26).jpg\n",
      "File: test (27).jpg\n",
      "File: test (28).jpg\n",
      "File: test (29).jpg\n",
      "File: test (3).jpg\n",
      "File: test (30).jpg\n",
      "File: test (31).jpg\n",
      "File: test (32).jpg\n",
      "File: test (33).jpg\n",
      "File: test (34).jpg\n",
      "File: test (35).jpg\n",
      "File: test (36).jpg\n",
      "File: test (37).jpg\n",
      "File: test (38).jpg\n",
      "File: test (39).jpg\n",
      "File: test (4).jpg\n",
      "File: test (40).jpg\n",
      "File: test (41).jpg\n",
      "File: test (42).jpg\n",
      "File: test (43).jpg\n",
      "File: test (44).jpg\n",
      "File: test (45).jpg\n",
      "File: test (46).jpg\n",
      "File: test (47).jpg\n",
      "File: test (48).jpg\n",
      "File: test (49).jpg\n",
      "File: test (5).jpg\n",
      "File: test (50).jpg\n",
      "File: test (51).jpg\n",
      "File: test (52).jpg\n",
      "File: test (53).jpg\n",
      "File: test (54).jpg\n",
      "File: test (55).jpg\n",
      "File: test (56).jpg\n",
      "File: test (57).jpg\n",
      "File: test (58).jpg\n",
      "File: test (59).jpg\n",
      "File: test (6).jpg\n",
      "File: test (60).jpg\n",
      "File: test (61).jpg\n",
      "File: test (62).jpg\n",
      "File: test (63).jpg\n",
      "File: test (64).jpg\n",
      "File: test (65).jpg\n",
      "File: test (66).jpg\n",
      "File: test (67).jpg\n",
      "File: test (68).jpg\n",
      "File: test (69).jpg\n",
      "File: test (7).jpg\n",
      "File: test (70).jpg\n",
      "File: test (71).jpg\n",
      "File: test (72).jpg\n",
      "File: test (73).jpg\n",
      "File: test (74).jpg\n",
      "File: test (75).jpg\n",
      "File: test (76).jpg\n",
      "File: test (77).jpg\n",
      "File: test (78).jpg\n",
      "File: test (79).jpg\n",
      "File: test (8).jpg\n",
      "File: test (80).jpg\n",
      "File: test (81).jpg\n",
      "File: test (82).jpg\n",
      "File: test (83).jpg\n",
      "File: test (84).jpg\n",
      "File: test (85).jpg\n",
      "File: test (86).jpg\n",
      "File: test (87).jpg\n",
      "File: test (88).jpg\n",
      "File: test (89).jpg\n",
      "File: test (9).jpg\n",
      "File: test (90).jpg\n",
      "File: test (91).jpg\n",
      "File: test (92).jpg\n",
      "File: test (93).JPG\n",
      "File: test (94).jpg\n",
      "File: test (95).jpg\n",
      "File: test (96).jpg\n",
      "File: test (97).jpg\n",
      "File: test (98).jpg\n",
      "File: test (99).jpg\n"
     ]
    }
   ],
   "source": [
    "# Test on test_images in demo folder and save the output in output folder.\n",
    "path = \"../demo2/\"\n",
    "import glob\n",
    "import PIL.Image\n",
    "image_names=sorted(os.listdir(path))\n",
    "NumbSeq=len(image_names)\n",
    "for i in range(0,NumbSeq):\n",
    "    print('File:', os.path.basename(image_names[i]))\n",
    "    img = PIL.Image.open(path + image_names[i])\n",
    "    imgSize = img.size\n",
    "    img=img.convert('RGB')\n",
    "    img=np.array(img)\n",
    "    #img = mpimg.imread(path + image_names[i])\n",
    "    rclasses, rscores, rbboxes =  process_image(img)\n",
    "    visualization.plt_bboxes(os.path.basename(image_names[i]),img,rclasses , rscores, rbboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
