{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Aim of the Project\n",
    "\n",
    "To create a model which can be used to recognize and annotate cats in photos.  \n",
    "\n",
    "\n",
    "1. Train the model \n",
    "2. Applies the model onto test set of images (test_set.zip) and draws bounding boxes around cats on the test set as such:\n",
    "\n",
    "![](https://raw.githubusercontent.com/CMIST/HiringExercise_MLCVEngineer/master/catbb.png \"Alf with Lucky\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## SSD: Single Shot MultiBox Detector in TensorFlow\n",
    "\n",
    "### Why did I chose SSD ?\n",
    "\n",
    "Faster R-CNN, YOLO and Single Shot MultiBox Detector are the present state-of-the-art in using CNN for object detection.\n",
    "\n",
    "Even though there are a few differences between the three previous approaches, they share the same general pipeline. Namely, the detection network is designed based on the following rules:\n",
    "\n",
    "Use a deep convolutional network trained on ImageNet as a multi-scale source of features. Typically, VGG, ResNet or Inception;\n",
    "\n",
    "Provide a collection of pre-defined anchors boxes tiling the image at different positions and scales. They serve the same purpose as the sliding window approach in classic CV detection algorithms;\n",
    "\n",
    "For every anchor box, the modified CNN provides a probability for every class of object (and a no detection probability), and offsets (x, y, width and height) between the detected box and the associated anchor box.\n",
    "\n",
    "The detection output of the network is post-processed using a Non-Maximum Selection algorithm, in order to remove overlapping boxes.\n",
    "\n",
    "For this project, I chose SSD detector, as the later provides a good compromise between accuracy and speed (note that the last YOLOv2 article describes in fact a SSD-like network).\n",
    "\n",
    "## What is SSD?\n",
    "\n",
    "It is  method for detecting objects in images using a single deep neural network. This approach discretizes the output space of bounding boxes into a set of default boxes over different aspect ratios and scales per feature map location. At prediction time, the network generates scores for the presence of each object category in each default box and produces adjustments to the box to better match the object shape. Additionally, the network combines predictions from multiple feature maps with different resolutions to naturally handle objects of various sizes. The model is simple relative to methods that require object proposals because it completely eliminates proposal generation and subsequent pixel or feature resampling stage and encapsulates all computation in a single network. This makes SSD easy to train and straightforward to integrate into systems that require a detection component. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## SSD architecture\n",
    "\n",
    "The architecture of the project is modular, and should make easy the implementation and training of other SSD variants (ResNet or Inception based for instance). Present TF checkpoints have been directly converted from SSD Caffe models.\n",
    "\n",
    "As previously outlined, the SSD network used the concept of anchor boxes for object detection. The image below illustrates the concept: at several scales are pre-defined boxes with different sizes and ratios. The goal of SSD convolutional network is, for each of these anchor boxes, to detect if there is an object inside this box (or closely), and compute the offset between the object bounding box and the fixed anchor box.\n",
    "\n",
    "\n",
    "In the case of SSD network, we use VGG as a based architecture: it provides high quality features at different scales, the former being then used as inputs for multibox modules in charge of computing the object type and coordinates for each anchor boxes. The architecture of the network we use is illustrated in the following TensorBoard graph. It follows the original SSD paper:\n",
    "\n",
    "\n",
    "Implementation of the SSD VGG-based 512 network.\n",
    "    The default features layers with 512x512 image input are:\n",
    "      conv4 ==> 64 x 64\n",
    "      conv7 ==> 32 x 32\n",
    "      conv8 ==> 16 x 16\n",
    "      conv9 ==> 8 x 8\n",
    "      conv10 ==> 4 x 4\n",
    "      conv11 ==> 2 x 2\n",
    "      conv12 ==> 1 x 1\n",
    "    The default image size used to train this network is 512x512.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## SSD Training and Testin Scripts\n",
    "\n",
    "### Approach \n",
    "\n",
    "As Training the network was computationally expensive in my system I have chose to load the network with pretrained weights from \n",
    "the follwing check point. But I have included the script to train and fine tune the network.\n",
    "\n",
    "This model implements VGG-based SSD networks (with 300 and 512 inputs). Present TF checkpoints have been directly converted from SSD Caffe models.I had stared with 300 input checkpoints but found the detection rate was not satisfactory and so adopted the 512 inputs checkpoint.\n",
    "\n",
    "\n",
    "## Testing \n",
    "\n",
    "The [SSD Notebook](notebooks/single_shot_detector.ipynb) contains SSD TensorFlow pipeline to apply the model onto test set of images (test_set.zip) and draws bounding boxes around cats on the test set . \n",
    "\n",
    "Shortly, the detection is made of two main steps: \n",
    "\n",
    "Running the SSD network on the image and \n",
    "Post-processing the output using common algorithms (top-k filtering and Non-Maximum Suppression algorithm).\n",
    "\n",
    "Here are two examples of successful detection outputs:\n",
    "![](notebooks/pictures/ex1.jpg \"SSD anchors\")\n",
    "![](notebooks/pictures/ex2.jpg \"SSD anchors\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "[SSD Notebook](notebooks/Training Script.ipynb) contains the script for training the model \n",
    "\n",
    "1. Data for training can be downloaded from the site http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\n",
    "\n",
    "\n",
    "2. The current version only supports Pascal VOC datasets (2007 and 2012). In order to be used for training a SSD model, the former need to be converted to TF-Records using the [Convert Data to tfr format](tf_convert_data.py) tf_convert_data.py script:this step will have generated a collection of TF-Records instead of a single file in order to ease shuffling during training.\n",
    "\n",
    "3. The script train_ssd_network.py is in charged of training the network. Similarly to TF-Slim models, one can pass numerous options to the training process (dataset, optimiser, hyper-parameters, model, ...). In particular, it is possible to provide a checkpoint file which can be use as starting point in order to fine-tune a network.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Output:\n",
    "\n",
    "The test set of different file formats was successfully run through the model and a satisfactory detection of cats was attained and bounding boxes were drawn around the cats. The output is save in the folder [Output](./Output)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How I improved on accuracy?\n",
    "\n",
    "My initial submission a week ago was on the Tiny YOLO model. Which was giving me a fairly poor detection rate.\n",
    "\n",
    "#### Why SSD over YOLO .\n",
    "    \n",
    "SSD model adds several feature layers to the end of a base network, which predict the offsets to default boxes of different scales and aspect ratios and their associated confidences. SSD with a 300 × 300 input size significantly outperforms its 448 × 448 YOLO counterpart in accuracy on VOC2007 test while also improving the speed.The box position relative to each feature map location (cf the architecture of YOLO that uses an intermediate fully connected layer instead of a convolutional filter for this step).\n",
    "\n",
    "####  Why SSD 512x512 over SSD 300x300\n",
    "indeed SSD with a 300 x300 input size was defenitely better than the YOLO detection but in my search for perfection I could see the SSD with 512x 512 could give a more precise output.Increasing the input size (e.g. from 300×300 to 512×512) can help improve detecting small objects, but there is still a lot of room to improve. SSD performs really well on large objects. And it is very robust to different object aspect ratios because default boxes of various aspect ratios are used per feature map location.\n",
    "\n",
    "Within this model playing around with threshold value lately set to 0.2 and nms threshold(NMS is therefore to retain only one window per group, corresponding to the precise local maximum of the response function, ideally obtaining only\n",
    "one detection per object) lately set to 0.45 could improve the detection. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Areas of Improvement:\n",
    "\n",
    "This network is designed to detect 21 object classes. We could design and train a smaller network to work only on cats. This will reduce time required for forward pass.\n",
    "\n",
    "Better Hardware\n",
    "This code was run on a i5 8GB laptop, without GPU support. If run on a faster machine with GPU support the frame rate can be increased."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
